# -*- coding: utf-8 -*-
"""Copy of AICoachChatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zs6Wqob2JFpqkdrbUFPaS_yXW3Hv94hm
"""

#pip install -U streamlit langchain langchain-openai langchain-community PyPDF2 faiss-cpu sentence-transformers

import streamlit as st
import PyPDF2
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.text_splitter import CharacterTextSplitter
import os
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# Safely load the API key from secrets
if "OPENAI_API_KEY" not in st.secrets:
    st.error("‚ùå OpenAI API key not found. Please set it in Streamlit secrets.")
    st.stop()

openai_api_key = st.secrets["OPENAI_API_KEY"]

# Initialize the LLM
llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=openai_api_key)


# Prompt template
resume_prompt = PromptTemplate(
    input_variables=["resume"],
    template="""
Role: You are an AI Career Coach.

Task: Given the candidate's resume, provide a comprehensive summary that includes:
- Career Objective
- Skills and Expertise
- Professional Experience
- Educational Background
- Notable Achievements

Resume:
{resume}
"""
)

resume_analysis_chain = LLMChain(llm=llm, prompt=resume_prompt)

# Helpers
def extract_text_from_pdf(pdf_file):
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

embeddings = HuggingFaceEmbeddings()
text_splitter = CharacterTextSplitter(separator='\n', chunk_size=2000, chunk_overlap=200, length_function=len)

def analyze_resume(text):
    return resume_analysis_chain.invoke({"resume": text})["text"]

def ask_question(text, question):
    texts = text_splitter.split_text(text)
    db = FAISS.from_texts(texts, embeddings)
    retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 4})
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever, return_source_documents=False)
    return qa_chain.invoke(question)["result"]

# Streamlit UI
st.title("ü§ñ AI Career Coach")
st.markdown("Upload your resume and ask career-related questions.")

uploaded_file = st.file_uploader("Upload your Resume (PDF)", type="pdf")

if uploaded_file:
    resume_text = extract_text_from_pdf(uploaded_file)
    st.success("Resume uploaded successfully!")

    if st.button("Generate Resume Summary"):
        with st.spinner("Analyzing resume..."):
            summary = analyze_resume(resume_text)
            st.text_area("üìÑ Resume Summary", value=summary, height=300)

    question = st.text_input("Ask a question about your resume:")
    if question:
        with st.spinner("Thinking..."):
            answer = ask_question(resume_text, question)
            st.text_area("üí¨ AI Coach Answer", value=answer, height=200)
